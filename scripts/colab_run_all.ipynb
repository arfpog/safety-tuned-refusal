{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "intro"
   },
   "source": [
    "# Safety-tuned refusal: end-to-end Colab\n",
    "Run setup → prompts → multi-sample responses → Gemini judging → bootstrap P(safety) → probe analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "config"
   },
   "outputs": [],
   "source": [
    "#@title Configure paths and defaults\n",
    "import os\n",
    "REPO_URL = \"https://github.com/yourname/safety-tuned-refusal.git\"  # change if needed\n",
    "WORKDIR = \"/content/safety-tuned-refusal\"\n",
    "DATA_DIR = os.path.join(WORKDIR, \"data\")\n",
    "MODEL_NAME = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "N_SAMPLES = 5\n",
    "TEMPERATURE = 0.7\n",
    "MAX_NEW_TOKENS = 256\n",
    "BATCH_SIZE = 4\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\", \"\")\n",
    "HF_TOKEN = os.getenv(\"HF_TOKEN\", \"\")\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "PROMPTS_PATH = os.path.join(DATA_DIR, \"prompts.csv\")\n",
    "RESPONSES_PATH = os.path.join(DATA_DIR, \"responses_aligned.csv\")\n",
    "LABELED_PATH = os.path.join(DATA_DIR, \"responses_aligned_labeled.csv\")\n",
    "BOOTSTRAP_OUT = os.path.join(DATA_DIR, \"identity_bootstrap.csv\")\n",
    "ANALYSIS_PREFIX = os.path.join(DATA_DIR, \"outputs/llama3\")\n",
    "print(\"Config loaded\", WORKDIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "clone_install"
   },
   "outputs": [],
   "source": [
    "#@title Clone repo (if needed) and install\n",
    "import sys\n",
    "if not os.path.exists(WORKDIR):\n",
    "    !git clone $REPO_URL $WORKDIR\n",
    "%cd $WORKDIR\n",
    "!pip install -q -e .\n",
    "if HF_TOKEN:\n",
    "    from huggingface_hub import login\n",
    "    login(token=HF_TOKEN, add_to_git_credential=True)\n",
    "if GOOGLE_API_KEY:\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
    "print(\"Ready. HF token set?\", bool(HF_TOKEN), \"Gemini key set?\", bool(os.getenv(\"GOOGLE_API_KEY\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "prompts"
   },
   "outputs": [],
   "source": [
    "#@title Generate prompts CSV\n",
    "!safety-tuned-refusal generate-prompts --output $PROMPTS_PATH\n",
    "!head -n 5 $PROMPTS_PATH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "responses"
   },
   "outputs": [],
   "source": [
    "#@title Generate multi-sample responses (GPU-heavy)\n",
    "!safety-tuned-refusal generate-responses --prompts $PROMPTS_PATH --output $RESPONSES_PATH --model $MODEL_NAME --temperature $TEMPERATURE --n-samples $N_SAMPLES --max-new-tokens $MAX_NEW_TOKENS\n",
    "!wc -l $RESPONSES_PATH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "judge"
   },
   "outputs": [],
   "source": [
    "#@title Judge with Gemini (set GOOGLE_API_KEY)\n",
    "assert os.getenv(\"GOOGLE_API_KEY\"), \"Set GOOGLE_API_KEY env before judging\"\n",
    "!safety-tuned-refusal judge --responses $RESPONSES_PATH --output $LABELED_PATH\n",
    "!wc -l $LABELED_PATH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bootstrap"
   },
   "outputs": [],
   "source": [
    "#@title Bootstrap P(safety) by identity\n",
    "!safety-tuned-refusal report-safety --labeled-responses $LABELED_PATH --risk-level all --output $BOOTSTRAP_OUT\n",
    "import pandas as pd\n",
    "display(pd.read_csv(BOOTSTRAP_OUT).head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "analyze"
   },
   "outputs": [],
   "source": [
    "#@title Probe analysis (heavy; uses model again)\n",
    "!mkdir -p $(dirname $ANALYSIS_PREFIX)\n",
    "!safety-tuned-refusal analyze --labeled-responses $LABELED_PATH --model $MODEL_NAME --batch-size $BATCH_SIZE --save-prefix $ANALYSIS_PREFIX\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "drive"
   },
   "outputs": [],
   "source": [
    "#@title Optional: copy outputs to Drive\n",
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\")\n",
    "!cp -r $DATA_DIR /content/drive/MyDrive/safety_tuned_refusal_outputs\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
